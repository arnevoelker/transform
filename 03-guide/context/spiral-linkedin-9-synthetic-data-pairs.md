# Synthetic Data Pairs for LinkedIn Posts

## Beispiel 1

### Input

KI-Content und AuthentizitÃ¤t

**Kernaussage**: Die Frage, ob KI-generierter Content "mit Liebe gemacht" sein kann, fÃ¼hrt zu einer tieferen Reflexion Ã¼ber QualitÃ¤t und menschlichen Mehrwert in der Content-Erstellung.

**Kontext**: Viele Menschen verÃ¶ffentlichen unbearbeitete KI-Outputs, was die Content-QualitÃ¤t im Internet senkt. Relevant fÃ¼r alle Content-Creators, die KI nutzen wollen ohne ihre AuthentizitÃ¤t zu verlieren.

**Anwendung**: KI sollte als Werkzeug genutzt werden, nicht als Ersatz fÃ¼r menschliche KreativitÃ¤t. Der Mensch bleibt wichtig beim Sammeln echter Erfahrungen und beim Kuratieren der KI-Outputs.

**Originalzitat**: Â«Hello, is There any Value Out There?Â»

### Output

Wenn es mit KI gemacht ist, ist es dann mit Liebe gemacht?

Eine Frage, die mir keine Ruhe lÃ¤sst:

Denn ich bin Fan von kÃ¼nstlicher Intelligenz. Aber nicht von dem belanglosen Zeugs, das beim ersten Entwurf herauskommt â€“ und das leider zu viele Menschen 1:1 verÃ¶ffentlichen.

Ich weiss, es geht besser. Darum forsche ich daran:

â€“ was wir in Ruhe den Maschinen Ã¼berlassen kÃ¶nnen
Etwa, damit sie uns das Leben leichter machen. Uns die Arbeiten abnehmen, die wir langweilig finden und ermÃ¼dend. Und die wir darum vielleicht Ã¼berhaupt nicht getan hÃ¤tten.

â€“ und wo es uns braucht, damit es gut wird 
Zum Beispiel vor dem Schreiben, wenn wir mehr Echtes einfangen, sammeln, kuratieren. Und danach â€“ wenn wir auswÃ¤hlen und bewerten, was die KI geliefert hat.

Manchmal schaue ich auf, blicke in eine Welt voller AI-Slop und frage mich: 

Bin ich allein auf meiner Suche?

Zum GlÃ¼ck entdecke ich immer wieder auch Inhalte, die mir sagen: Es gibt sie noch, die guten Content-Creators. Die nicht nur fragen: Was kann ich als NÃ¤chstes verÃ¶ffentlichen? Sondern die fragen: Bringt das mein Publikum weiter?

Kurz: Hello, is There any Value Out There?

In diesem Sinne freue ich mich auf die neue Staffel von The Animalz Content Podcast mit Ty Magnin und Tim Metz. Die Folge zum Kick-off steht schon bereit, wo immer du deine Podcasts hÃ¶rst. Morgen geht es dann los mit GÃ¤sten. Als Erster:

Nathan Baschez, GrÃ¼nder von Lex (Dienstag, 4. MÃ¤rz)

Mit seiner Textverarbeitung Lex hat Nathan konsequent vorgefÃ¼hrt, dass KI nicht in einem Chat stattfinden muss. Sondern dass du beim Schreiben weiter in einer FlÃ¤che arbeiten kannst (und deinem Text zuliebe tun solltest.) Inzwischen hat das ja auch OpenAI begriffen und bietet uns Canvas. FÃ¼r Profis ist Lex immer noch die bessere Wahl.

Ich freue mich auf echte Einblicke â€“ von Menschen, die wissen, wie man KI am besten nutzt (und wo lieber nicht.)

## Beispiel 2

### Input

Schreib-KI Vergleich: GPT vs Claude

**Kernaussage**: Direkter Vergleich zwischen GPT-4.5 und Claude Sonnet 3.7 fÃ¼r Schreibaufgaben, mit klaren StÃ¤rken und SchwÃ¤chen beider Modelle.

**Kontext**: Neue KI-Modelle werden stÃ¤ndig released. Content-Creators brauchen praktische Orientierung, welches Tool fÃ¼r welchen Zweck am besten geeignet ist.

**Anwendung**: GPT-4.5 hat im Stil aufgeholt, Claude bleibt bei langen Texten Ã¼berlegen. Die Wahl hÃ¤ngt vom spezifischen Use Case ab.

**Originalzitat**: Â«Claude war letzten Sommer der absolute Star â€“ ist aber kontinuierlich schlechter geworden.Â»

### Output

GPT-4.5 oder Claude Sonnet 3.7
Welches ist besser zum Schreiben?

Zwei neue Modelle, eine grosse Frage. ChatGPT-4.5 behauptet von sich selbst, es sei gemacht zum Schreiben â€“ und zum Erforschen von Ideen. Der Favorit der Schreibenden war in letzter Zeit aber Claude Sonnet 3.5

Ist Claude Sonnet jetzt entthront? 
Kann Version 3.7 noch mithalten im Kampf mit dem absurd teuren GPT-4.5?

Kurze Antwort in zwei Dimensionen:


hashtag
#stil Claude verliert seinen Vorsprung 
Claude war letzten Sommer der absolute Star â€“ ist aber kontinuierlich schlechter geworden. Mit GPT-4.5 hat OpenAI aufgeholt. Ist das gut genug? Das muss der Dauertest zeigen.


hashtag
#konsistenz Claude gewinnt in der langen Form
Bei langem Input war Claude schon immer besser als OpenAI. Jetzt kann Claude ausserdem brutal langen Output. Wenn du Whitepaper produzierst oder BÃ¼cher, dann musst du dir das ansehen. 

Die Details hier im Video â€“ ich bin gespannt auf deine EindrÃ¼cke

## Beispiel 3

### Input

Ideenfindung ohne KI

**Kernaussage**: Bei kreativer Blockade ist KI oft kontraproduktiv. Bessere Alternativen sind datenbasierte Insights oder persÃ¶nliche Motivation.

**Kontext**: Viele greifen reflexartig zu ChatGPT bei Schreibblockaden. Das kann aber zu mehr Verwirrung fÃ¼hren statt zu Klarheit.

**Anwendung**: Nutze Analytics-Daten oder wandle erfolgreiche Kommentare in BeitrÃ¤ge um, statt KI nach Ideen zu fragen.

**Originalzitat**: Â«Machen Sie aus diesem Kommentar einen Beitrag zu diesem Thema.Â»

### Output

Wenn du keine Idee hast, dann frag nicht ChatGPT

Du weisst nicht, was schreiben? Angeblich hilft dann KI, etwa gegen die Angst vor dem weissen Blatt. SchÃ¶n, wenn das bei dir klappt.

Bei mir fÃ¼hrt es direkt in die Verwirrung. 

Mit ChatGPT & Co wird bei mir das Blatt dann zwar voll, aber ich kann mich erst recht nicht entscheiden: 

- Was ist wichtig?
- Was stimmt Ã¼berhaupt?
- Und wie setze ich hier PrioritÃ¤ten?

Was mir einen Sinn fÃ¼r PrioritÃ¤ten geben kÃ¶nnte, das wÃ¤ren:

â€“ harte Daten zum Publikums-Interesse
(Etwa Suchvolumen, Impressionen, Engagement)

â€“ eine klare Idee von einem Warum
(Mit ganz subjektiven Daten: diesem GefÃ¼hl in mir)

Und so ein Warum spÃ¼re ich immer dann, wenn ich den Wunsch habe, einen fremden Beitrag zu kommentieren.

Darum hat LinkedIn schon recht, wenn es mir vorschlÃ¤gt:
Â«Machen Sie aus diesem Kommentar einen Beitrag zu diesem Thema.Â»

Und, na klar:

Ich will gerne meine Kommentare in BeitrÃ¤ge verwandeln.
Nur nicht sofort.
Und nicht jeden.

Was ich darum stattdessen tue:
Oft gehe ich zurÃ¼ck, blÃ¤ttere durch meine Kommentare und frage mich: 
Ist dies ein Gedanke, den ich gerne noch ein wenig vertiefen mÃ¶chte?

Und umso mehr wÃ¼rde ich mich freuen, wenn kommt, was Jasmin AliÄ‡ hier kommen sieht:

Analytics fÃ¼r Kommentare

So wÃ¼rden endlich beide GrÃ¼nde zusammenfinden:

â€“ Validierte Daten zum Interesse
â€“ Mein GefÃ¼hl, warum mir das wichtig ist

(Hier nur als Screenshot â€“ Link in den Kommentaren)

## Beispiel 4

### Input

Die Umkehrung der Prompts

**Kernaussage**: Prompts waren frÃ¼her DenkanstÃ¶ÃŸe fÃ¼r Menschen, nicht Befehle an Maschinen. Diese Perspektive kann unsere KreativitÃ¤t neu beleben.

**Kontext**: Vor ChatGPT (pre-2020) waren Prompts kreative Aufgaben in BÃ¼chern fÃ¼r Schreibende. Diese historische Perspektive zeigt eine Alternative zur heutigen KI-Fixierung.

**Anwendung**: Statt Antworten von der KI zu verlangen, lass dir inspirierende Fragen stellen, die dein eigenes Denken anregen.

**Originalzitat**: Â«Frage nicht deine Maschine nach einer Antwort. Sondern bitte deine Maschine um eine Frage.Â»

### Output

FrÃ¼her war alles besser.

Vor allem die Prompts:

Ein Prompt ist, was wir der KI geben, damit sie uns Antworten liefert. Diese Definition hat sich durchgesetzt, seit ChatGPT auf der Welt ist. Aber Prompts von vor 2020 zeigen: 

Es ist noch gar nicht so lange her, da war es genau andersherum.

- Da haben nicht Maschinen fÃ¼r uns gedacht.
- Nicht der KÃ¼nstlichen Intelligenz wurden Fragen gestellt.
- Menschen, die denken wollten, haben sich Aufgaben stellen lassen. 

Wenn etwas dringend ist, dann stellen sich die Fragen ja in der Regel von selbst. Aber bei anderen wichtigen Fragen im Leben weisst du vielleicht nicht einmal, wo anfangen. 

FÃ¼r alle Gelegenheiten, in denen du den Wald vor lauter BÃ¤umen nicht siehst â€“ und fÃ¼r solche Aufgaben, bei denen du etwas grundlegend Neues entdecken wolltest, gab es solche Aufgaben in BÃ¼chern:

Sammlungen von Prompts.

Nein, die Titel im Bild sind kein Ranking der besten Prompts aller Zeiten. Sie dienen nur als kleine Anregung, dass du auch selber nach inspirierenden Fragestellungen suchen kannst. 

Damit dann in deinem Denken, in deinem Schreiben etwas entstehen kann, das grÃ¶sser ist als du:

- Fiktive Welten
- Plots fÃ¼r Geschichten
- Tiefere Erkenntnis Ã¼ber dich selbst

Darum probiere doch zur Abwechslung heute einmal etwas Anderes:

Frage nicht deine Maschine nach einer Antwort.

Sondern bitte deine Maschine um eine Frage.

## Beispiel 5

### Input

KI-Text Erkennbarkeit

**Kernaussage**: Wenn professionelle Texte zu perfekt sind, wirken sie wie KI-generiert. Die LÃ¶sung liegt nicht in kÃ¼nstlichen Fehlern, sondern in einzigartigen Gedanken.

**Kontext**: Professionelle Schreiber werden zunehmend verdÃ¤chtigt, KI zu nutzen, nur weil ihre Texte grammatikalisch korrekt sind. Das verschiebt die QualitÃ¤tsdiskussion.

**Anwendung**: Differenziere dich durch originelle Gedanken, nicht durch Schreibfehler. Die Messlatte fÃ¼r menschlichen Content liegt jetzt hÃ¶her.

**Originalzitat**: Â«Dass es menschlich tÃ¶nt, ist heute nicht mehr menschlich genug.Â»

### Output

Kurze SÃ¤tze, keine Fehler:
Stammt dieser Text aus der KI?

Heute fÃ¤llt allen auf, wenn etwas so aussieht wie von KI geschrieben. Liegt es daran, dass die SÃ¤tze korrekt sind? Oder daran, dass zu viele Doppelpunkte und Gedankenstriche im Text erscheinen? 

Aber was, wenn du Profi bist? 

Wenn du leider aus Versehen viel zu richtig schreibst? Dann kÃ¶nnten Menschen glauben, dein Post sei von der Maschine geschrieben, dabei hast du 
jedes.
einzelne. 
Wort. 
von.
Hand. 
getippt?

Wenn deine Leser dann finden, das tÃ¶nt aber nach KI, dann kann es nicht daran liegen, dass die Grammatik besonders richtig war. Und dann kann die LÃ¶sung auch nicht darin liegen, extra ein paar Tippfehler einzubauen.

Denn dann geht es nicht mehr um die QualitÃ¤t der Sprache â€“ sondern um die QualitÃ¤t des Gedankens.

Wenn du zum Thema Marketing erzÃ¤hlst, was Simon Sinek und Seth Godin schon hundert Mal erzÃ¤hlt haben, dann hÃ¤ttest du es nicht von Hand schreiben mÃ¼ssen â€“ ChatGPT hÃ¤tte das auch gekonnt.

Hart, aber wahr:

Wenn kÃ¼nstliche Intelligenz das Banale gut ausdrÃ¼cken kann â€“ dann liegt die Messlatte plÃ¶tzlich hÃ¶her.: Ich muss jetzt andere Dinge sagen. Sonst habe ich keine Chance, mich von der Maschine zu unterscheiden.

Aber wie schaffe ich das?

Es gibt ein paar Methoden, mit denen wir mehr Mensch in unsere Storys bringen. Sogar in solche Texte, an denen die KI mithilft. Bleib dran, und im Laufe der Woche erfÃ¤hrst du mehr. Denn:

Dass es menschlich tÃ¶nt, ist heute nicht mehr menschlich genug.

PS: Bevor ich damit loslege, heute vorab die wichtigste Frage: Hast du eine Lieblings-Methode, mit der du mehr von dir in deinen Content bringst?

## Beispiel 6

### Input

Deep Research Praxistest

**Kernaussage**: 5-tÃ¤giger Praxistest von Deep Research Tools zeigt: Sie produzieren viel Content mit fragwÃ¼rdigen Quellen. Selber denken bleibt unverzichtbar.

**Kontext**: Deep Research wird als Game-Changer fÃ¼r Content-Recherche gehyped. Ein kritischer Praxistest zeigt die RealitÃ¤t hinter dem Hype.

**Anwendung**: Nutze Deep Research als Sprungbrett fÃ¼r eigene Gedanken, nicht als Faktenquelle. Alle Quellen mÃ¼ssen manuell geprÃ¼ft werden.

**Originalzitat**: Â«Die Deep Researcher halluzinieren â€“ alle.Â»

### Output

Deep Research: 

Ich habe es ausprobiert, damit du es nicht tun musst


FÃ¼nf Tage mit ChatGPT, Gemini, Perplexity und Grok: In denen habe ich ausprobiert, was Deep Research kann â€“ und was nicht. Das Ergebnis ist noch lange nicht abschliessend, aber hier schon mal das Wichtigste in KÃ¼rze:


01/ Links sind keine Fakten

Es gibt Leute da draussen, die sagen, mit Deep Research musst du nie mehr Fakten prÃ¼fen. Manche posten das sogar auf LinkedIn ğŸ™ˆ Aber das stimmt Ã¼berhaupt nicht. Die Deep Researcher halluzinieren â€“ alle. Manche Quellen existieren definitiv nicht. Und wenn eine Quelle nicht existiert, heisst das, du musst alle prÃ¼fen.


02/ Falsche Fakten, echte Ãœberforderung

Deep Research produziert eine Menge Lesestoff in einer unglaublichen Geschwindigkeit. Die Frage ist, kannst du das alles lesen? Und ja, das musst du. Ob ein Link nicht existiert, das merkst du beim ersten Klick. Ob du der Quelle vertrauen kannst, weisst du nur, wenn du sie prÃ¼fst. Viel Spass dabei, jeder Information nachzugehen.


03/ Mehr Wissen, weniger Weisheit

Deep Research fehlt eine ganz wesentliche Quelle: Es kennt dich nicht. Deep Research bringt dir eine Menge Wissen auf den Tisch, aber es ist weiter von Weisheit entfernt als je zuvor. Es hat nur Zugriff auf Ã¶ffentliche Seiten im Netz. Es kennt weder die Journals hinter der Paywall, die du liest, noch die Guidelines deiner Firma. Jedes Talk-to-your-PDF ist klÃ¼ger als das.


04/ Perfektion ist Illusion 

Vor allem das teure ChatGPT Pro erzeugt polierte Berichte, die perfekt aussehen. Zu perfekt, finde ich. Denn: Diese Perfektion ist eine Illusion. 

â€“ Auf die Gefahr, mich zu wiederholen:
Du weisst noch immer nicht, ob die Fakten Fakten sind
Du kannst kein gesichertes Wissen beisteuern
Du kannst unmÃ¶glich alles Ã¼berprÃ¼fen


05/ Je roher, desto Sprungbrett

Perplexity und Grok sind schnell und roh. Das finde ich gut. Denn: Je roher das Ergebnis, desto besser. Denn dann ist es brutal ehrlich und du weisst sofort, woran du bist. Und was du in so einem Report vor dir hast: Ein gutes Sprungbrett, um selbst weiter zu denken. Mit mehr Recherche da draussen im Netz â€“ oder in den eigenen Einsichten, die du schon lange in dir trÃ¤gst.


Deep Research: 5 Tage Â· 5 Lektionen

Fazit:
Selber denken lohnt sich noch immer

## Beispiel 7

### Input

Deep Research Tool-Vergleich

**Kernaussage**: Deep Research Tools teilen sich in zwei Lager: "raw insights" (Perplexity, Grok) vs. "polished reports" (Gemini, ChatGPT). Die Wahl hÃ¤ngt vom Arbeitsstil ab.

**Kontext**: Bei der Vielzahl von Deep Research Tools brauchen Nutzer klare Orientierung, welches Tool zu ihrem Workflow passt.

**Anwendung**: Forscher/Journalisten profitieren von rohen, schnellen Insights. Analysten/Manager bevorzugen geschliffene Reports.

**Originalzitat**: Â«Welches Deep Research ist das Beste fÃ¼r dich?Â»

### Output

Rohe Insights oder geschliffene Reports?
So findest du das beste Research fÃ¼r dich:

Welches Deep Research ist das beste?

Google Gemini, OpenAI ChatGPT, Perplexity und Grok: Alle vier Research Agents liefern Ergebnisse, die auf Anhieb gut aussehen. Und davon so viele, dass ich dir eine qualitative Auswertung noch einen Moment schuldig bleiben muss.

Eine Frage kann ich dir allerdings jetzt schon beantworten:

Welches Deep Research ist das Beste fÃ¼r dich?

Denn etwas fÃ¤llt sofort auf: Der Stil und die Haltung, mit der die Research Agents ans Werk gehen. Und da bilden sich zwei klare Lager:

â€“ Hands-on raw insights: 
Perplexity und Grok

Perplexity und Grok rennen einfach mal los, lesen Massen von Quellen und kommen schnell mit einer ersten These zurÃ¼ck. Die ist roh an den Kanten, aber bietet ein gutes Sprungbrett fÃ¼r eine weitere Recherche. Du bist Forscher oder Journalist? Dann wirst du das schÃ¤tzen.

â€“ Hands-off polished reports: 
Gemini und ChatGPT

Bei diesen beiden gilt: Wer vorher klarer brieft, bekommt hinterher die geschliffeneren Reports. Beide verarbeiten weniger Quellen, verknÃ¼pfen sie aber stÃ¤rker miteinander und schreiben daraus Papers, die fast schon zu perfekt aussehen. Wenn du als Analyst klare Vorgaben schÃ¤tzt oder als Chef gewohnt bist, deine Recherchen zu delegieren â€“ hier bist du zu Hause.

FÃ¼r mich ist die Wahl klar:

Auf jeden Fall erst einmal mit Perplexity oder Grok hands-on selber recherchieren. (Vor allem, wenn ich mich im Thema noch gar nicht wirklich gut auskenne)

In einem zweiten Schritt dann vielleicht mit ChatGPT agentic einen Report erstellen lassen. (Damit aus den ersten Ideen ein Report entsteht, den niemand mehr angreift)

Welches Deep Research ist deine Wahl?

## Beispiel 8

### Input

Deep Research Ãœberforderung

**Kernaussage**: Die schiere Geschwindigkeit und Menge von KI-generierter Recherche kann zu mentaler Ãœberforderung fÃ¼hren statt zu Klarheit.

**Kontext**: Nach intensiver Nutzung von Deep Research Tools zeigt sich ein unerwartetes Problem: Information Overload durch KI.

**Anwendung**: Pausen und Reflexion sind wichtig. KI-Recherche braucht menschliche Verarbeitungszeit.

**Originalzitat**: Â«Diese Maschinen produzieren vor meinen Augen fremde Gedanken in einer Geschwindigkeit, mit der ich einfach nicht mehr mithalten kann.Â»

### Output

Nach zwei Tagen mit Deep Research:
Soll ich eigentlich noch selber denken?

Ich habe am Montag angekÃ¼ndigt, ich wÃ¼rde eintauchen in die Welt des Deep Research. 

Da dachte ich, ich erzÃ¤hle euch dann StÃ¼ck fÃ¼r StÃ¼ck davon, wofÃ¼r dieses Deep Research wirklich gut ist, wie sich die Modelle voneinander unterscheiden und nach welchen Kriterien wir Menschen messen kÃ¶nnen, was eigentlich ein gutes Ergebnis ist. 

Einfach How-to, ganz praktisch.

Stattdessen hat es mir die Sprache verschlagen.

Denn ich frage mich:
Lohnt es sich eigentlich noch, wenn ich selber denke? 

Ich schicke drei Deep Researcher los: Googles Gemini, OpenAIs ChatGPT und Perplexity. Sie liefern unermÃ¼dlich ein Ergebnis nach dem anderen. Und im Laufe von 4 Stunden bin ich komplett erschlagen.

Und dann kommt Elon Musk mit Grok 3.
ğŸ˜±

Ich brauche erst einmal einen Spaziergang. 
Und dann eine RomCom. 
Vielleicht kann ich morgen wieder selber denken?

Dieses GefÃ¼hl hatte ich sonst beim Denken selten. 
(Ausser, wenn das Denken zu viele Formeln enthÃ¤lt)

Dieses GefÃ¼hl hatte ich bisher vor allem dann, wenn ich mich fÃ¼r ein Parfum entscheiden muss. SpÃ¤testens beim vierten neuen Duft verliere ich den Ãœberblick. 
Und so geht es mir mit Deep Research. 

Diese Maschinen produzieren vor meinen Augen fremde Gedanken in einer Geschwindigkeit, mit der ich einfach nicht mehr mithalten kann.

Darum heute: 

Kein Screenshot. 
Kein kluger Ratschlag. 
Sondern einfach nur Ratlosigkeit. 

Und einfach mal abschalten.

## Beispiel 9

### Input

KI-Recherche vs. Journalismus

**Kernaussage**: Kann Deep Research echte journalistische Recherche ersetzen? Ein Test soll zeigen, wo die Grenzen der KI-Recherche liegen.

**Kontext**: KI hat bereits das Schreiben revolutioniert. Jetzt steht die Frage im Raum, ob auch investigative Recherche automatisiert werden kann.

**Anwendung**: Definiere klare Kriterien fÃ¼r Recherche-QualitÃ¤t bevor du KI-Tools bewertest.

**Originalzitat**: Â«Ist damit auch mein zweites Standbein weg?Â»

### Output

Recherche mit kÃ¼nstlicher Intelligenz:
So gut wie echte Journalisten?

â€“ Vor zwei Jahren haben wir gefragt:
Kann ChatGPT so gut schreiben wie echte Texter? 

â€“ Heute geht die Frage in die nÃ¤chste Runde:
Recherchiert Deep Research so gut wie echte Journalisten?

In den letzten zwei Jahren haben wir gesehen: Ja, kÃ¼nstliche Intelligenz kann mich ersetzen. Aber nur, wenn du mit gut genug zufrieden bist. Und nur, wenn es nur ums Schreiben geht.

Denn Recherchieren â€“ das hat die KI noch immer nicht kÃ¶nnen. 

Jetzt aber bringen die Grossen der Branche Produkte fÃ¼r Deep Research:
- erst Google Gemini
- dann OpenAI's ChatGPT
- und jetzt auch noch Perplexity

Ist damit auch mein zweites Standbein weg?

Ich habe mir das absurd teure OpenAI Pro besorgt und werde die drei Tools gegeneinander testen. Am Ende der Woche sehen wir der Wahrheit ins Gesicht.

Jetzt frage ich mich:

- Welche Cases soll ich testen? 
- Woran messen wir, wie gut Recherche ist?

Woran misst du gute Recherche? Was sind fÃ¼r dich die wichtigsten Kriterien? Wenn du magst, dann schreib es mir hier in die Kommentare